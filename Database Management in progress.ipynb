{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6db01abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import math\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dcc192",
   "metadata": {},
   "source": [
    "Unhash any command to run.\n",
    "Read in file. Drop unnecessary columns. Save copy where drop empty rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97a309de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file\n",
    "df = pd.read_excel('Parts and Dimesions.xlsx')\n",
    "#print(df.head)\n",
    "\n",
    "# Do not use the 'Operator' or 'Item_No' column\n",
    "df = df.drop(columns=['Item_No', 'Operator'])\n",
    "#print(df.head)\n",
    "\n",
    "# Remove rows with missing cells\n",
    "df_nomissing = df.dropna()\n",
    "\n",
    "# Print the updated DataFrame\n",
    "#print(df_nomissing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2984599",
   "metadata": {},
   "source": [
    "Outlier checks\n",
    "check for anything outside of 3 standard deviations over global values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a59c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14ae85e0",
   "metadata": {},
   "source": [
    "Outlier check\n",
    "check for anything outside of 3 standard deviations over sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0002c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85c3cff3",
   "metadata": {},
   "source": [
    "Outlier check\n",
    "Isolation Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b350f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63208479",
   "metadata": {},
   "source": [
    "Normalization methods\n",
    "MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd7da55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a3381a5",
   "metadata": {},
   "source": [
    "Normalization methods\n",
    "z-score normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47fba64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61f4e023",
   "metadata": {},
   "source": [
    "Normalization methods\n",
    "standard_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5eac96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8136fd9",
   "metadata": {},
   "source": [
    "Make method to randomly remove data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7807c16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomly_remove_indices(df, percentage):\n",
    "    # Calculate the number of indices to remove\n",
    "    num_indices = int(len(df) * percentage/100)\n",
    "\n",
    "    # split each column into its own df\n",
    "    dfL = df['x']\n",
    "    dfW = df['y']\n",
    "    dfH = df['z']\n",
    "\n",
    "    # Generate random indices to remove for each colu,m\n",
    "    indices_to_removeL = np.random.choice(dfL.index, size=num_indices, replace=False)\n",
    "    indices_to_removeW = np.random.choice(dfW.index, size=num_indices, replace=False)\n",
    "    indices_to_removeH = np.random.choice(dfH.index, size=num_indices, replace=False)\n",
    "\n",
    "    # Save the removed indices as groundTruth\n",
    "    groundTruthL = dfL.loc[indices_to_removeL].copy()\n",
    "    groundTruthW = dfW.loc[indices_to_removeW].copy()\n",
    "    groundTruthH = dfH.loc[indices_to_removeH].copy()\n",
    "\n",
    "    # Remove the indices from individual columns\n",
    "    newL = dfL.copy()\n",
    "    newL.loc[indices_to_removeL] = np.nan\n",
    "    newW = dfW.copy()\n",
    "    newW.loc[indices_to_removeW] = np.nan\n",
    "    newH = dfH.copy()\n",
    "    newH.loc[indices_to_removeH] = np.nan\n",
    "\n",
    "    def merge_dfs(df1, df2):\n",
    "        return pd.merge(df1, df2, left_index=True, right_index=True, how='outer')\n",
    "    \n",
    "    df_merged = reduce(merge_dfs, [newL, newW, newH])\n",
    "    df_mergedGT = reduce(merge_dfs, [groundTruthL, groundTruthW, groundTruthH])\n",
    "\n",
    "    return df_merged, df_mergedGT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7e2b1e",
   "metadata": {},
   "source": [
    "Data Imputation Methods\n",
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2337e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64d2032c",
   "metadata": {},
   "source": [
    "Data Imputation Methods\n",
    "MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ea13cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "204a661a",
   "metadata": {},
   "source": [
    "Data Imputation Methods\n",
    "Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4178561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae4ee5f5",
   "metadata": {},
   "source": [
    "Scoring Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb8da02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fab87ad8",
   "metadata": {},
   "source": [
    "Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e531a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
