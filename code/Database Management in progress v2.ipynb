{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db01abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.preprocessing\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import math\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b352ad",
   "metadata": {},
   "source": [
    "Unhash any command to run.\n",
    "Read in file. Drop unnecessary columns. Save copy where drop empty rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2107a722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file\n",
    "df = pd.read_excel('Parts and Dimesions.xlsx')\n",
    "#print(df.head)\n",
    "\n",
    "# Do not use the 'Operator' or 'Item_No' column\n",
    "df = df.drop(columns=['Item_No', 'Operator'])\n",
    "#print(df.head)\n",
    "\n",
    "# Remove rows with missing cells\n",
    "df_nomissing = df.dropna()\n",
    "\n",
    "# Print the updated DataFrame\n",
    "#print(df_nomissing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d3aaf0",
   "metadata": {},
   "source": [
    "Outlier checks\n",
    "check for anything outside of 2 standard deviations over global values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa415363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscoreGlobalOutlier(df, stdev_threshold):\n",
    "    # Calculate the z-score for each column\n",
    "    z_scores = stats.zscore(df)\n",
    "\n",
    "    # Identify outliers\n",
    "    outliers = z_scores > stdev_threshold\n",
    "\n",
    "    # Remove outliers from the DataFrame\n",
    "    df_global_outlier_removed = df[~outliers.any(axis=1)]\n",
    "\n",
    "    return df_global_outlier_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43e09b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Length  Width  Height\n",
      "0    102.67  49.53   19.69\n",
      "1    102.50  51.42   19.63\n",
      "2     95.37  52.25   21.51\n",
      "3     94.77  49.24   18.60\n",
      "4    104.26  47.90   19.46\n",
      "..      ...    ...     ...\n",
      "494   98.34  49.03   19.30\n",
      "495  101.24  49.03   20.96\n",
      "496   98.37  52.12   19.68\n",
      "498   94.16  48.39   21.60\n",
      "499  102.35  51.24   21.47\n",
      "\n",
      "[421 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df_outlierthreshold = df_nomissing.copy()\n",
    "df_noGlobalOutlier = zscoreGlobalOutlier(df_outlierthreshold, 2)\n",
    "print(df_noGlobalOutlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd44a2a",
   "metadata": {},
   "source": [
    "Outlier check\n",
    "check for anything outside of 2 standard deviations over sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438ee7b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bd1935f",
   "metadata": {},
   "source": [
    "Outlier check\n",
    "Isolation Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5a82aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc5013d1",
   "metadata": {},
   "source": [
    "Normalization methods\n",
    "MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942ade21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34396d64",
   "metadata": {},
   "source": [
    "Normalization methods\n",
    "z-score normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7616e896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zScoreNormalized(df):\n",
    "    z_scores = (df - df.mean()) / df.std()\n",
    "    df_normalized = (z_scores - z_scores.min()) / (z_scores.max() - z_scores.min())\n",
    "    return df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2701b178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Length     Width    Height\n",
      "0    0.751116  0.607335  0.501080\n",
      "1    0.742687  0.776386  0.488121\n",
      "2    0.389192  0.850626  0.894168\n",
      "3    0.359445  0.581395  0.265659\n",
      "4    0.829945  0.461538  0.451404\n",
      "..        ...       ...       ...\n",
      "494  0.536440  0.562612  0.416847\n",
      "495  0.680218  0.562612  0.775378\n",
      "496  0.537928  0.838998  0.498920\n",
      "498  0.329202  0.505367  0.913607\n",
      "499  0.735250  0.760286  0.885529\n",
      "\n",
      "[421 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df_zscoreNorm = df_noGlobalOutlier.copy()\n",
    "df_zScorNormalized = zScoreNormalized(df_zscoreNorm)\n",
    "print(df_zScorNormalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2652a77f",
   "metadata": {},
   "source": [
    "Normalization methods\n",
    "L2 Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dc9dddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2Normalization(df):\n",
    "    for column in df.columns:\n",
    "        reshaped_data = df[column]\n",
    "        normalized_column = reshaped_data / np.linalg.norm(reshaped_data)\n",
    "        df[column] = normalized_column\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd369609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Length     Width    Height\n",
      "0    0.050505  0.048480  0.047404\n",
      "1    0.050422  0.050330  0.047259\n",
      "2    0.046914  0.051142  0.051785\n",
      "3    0.046619  0.048196  0.044780\n",
      "4    0.051287  0.046884  0.046850\n",
      "..        ...       ...       ...\n",
      "494  0.048375  0.047990  0.046465\n",
      "495  0.049802  0.047990  0.050461\n",
      "496  0.048390  0.051015  0.047380\n",
      "498  0.046319  0.047364  0.052002\n",
      "499  0.050348  0.050153  0.051689\n",
      "\n",
      "[421 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df_l2norm = df_noGlobalOutlier.copy()\n",
    "df_L2Normalized = l2Normalization(df_l2norm)\n",
    "print(df_L2Normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc393b82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd7c29a6",
   "metadata": {},
   "source": [
    "Make method to randomly remove data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "410346d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def randomly_remove_indices(df, percentage):\\n    # Calculate the number of indices to remove\\n    num_indices = int(len(df) * percentage/100)\\n\\n    # split each column into its own df\\n    dfL = df['Length']\\n    dfW = df['Width']\\n    dfH = df['Height']\\n\\n    # Generate random indices to remove for each colunm\\n    indices_to_removeL = np.random.choice(dfL.index, size=num_indices, replace=False)\\n    indices_to_removeW = np.random.choice(dfW.index, size=num_indices, replace=False)\\n    indices_to_removeH = np.random.choice(dfH.index, size=num_indices, replace=False)\\n\\n    # Save the removed indices as groundTruth\\n    groundTruthL = dfL.loc[indices_to_removeL].copy()\\n    groundTruthW = dfW.loc[indices_to_removeW].copy()\\n    groundTruthH = dfH.loc[indices_to_removeH].copy()\\n\\n    # Remove the indices from individual columns\\n    newL = dfL.copy()\\n    newL.loc[indices_to_removeL] = np.nan\\n    newW = dfW.copy()\\n    newW.loc[indices_to_removeW] = np.nan\\n    newH = dfH.copy()\\n    newH.loc[indices_to_removeH] = np.nan\\n\\n    def merge_dfs(df1, df2):\\n        return pd.merge(df1, df2, left_index=True, right_index=True, how='outer')\\n    \\n    df_merged = reduce(merge_dfs, [newL, newW, newH])\\n    df_mergedGT = reduce(merge_dfs, [groundTruthL, groundTruthW, groundTruthH])\\n\\n    return df_merged, df_mergedGT\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def randomly_remove_indices(df, percentage):\n",
    "    # Calculate the number of indices to remove\n",
    "    num_indices = int(len(df) * percentage/100)\n",
    "\n",
    "    # split each column into its own df\n",
    "    dfL = df['Length']\n",
    "    dfW = df['Width']\n",
    "    dfH = df['Height']\n",
    "\n",
    "    # Generate random indices to remove for each colunm\n",
    "    indices_to_removeL = np.random.choice(dfL.index, size=num_indices, replace=False)\n",
    "    indices_to_removeW = np.random.choice(dfW.index, size=num_indices, replace=False)\n",
    "    indices_to_removeH = np.random.choice(dfH.index, size=num_indices, replace=False)\n",
    "\n",
    "    # Save the removed indices as groundTruth\n",
    "    groundTruthL = dfL.loc[indices_to_removeL].copy()\n",
    "    groundTruthW = dfW.loc[indices_to_removeW].copy()\n",
    "    groundTruthH = dfH.loc[indices_to_removeH].copy()\n",
    "\n",
    "    # Remove the indices from individual columns\n",
    "    newL = dfL.copy()\n",
    "    newL.loc[indices_to_removeL] = np.nan\n",
    "    newW = dfW.copy()\n",
    "    newW.loc[indices_to_removeW] = np.nan\n",
    "    newH = dfH.copy()\n",
    "    newH.loc[indices_to_removeH] = np.nan\n",
    "\n",
    "    def merge_dfs(df1, df2):\n",
    "        return pd.merge(df1, df2, left_index=True, right_index=True, how='outer')\n",
    "    \n",
    "    df_merged = reduce(merge_dfs, [newL, newW, newH])\n",
    "    df_mergedGT = reduce(merge_dfs, [groundTruthL, groundTruthW, groundTruthH])\n",
    "\n",
    "    return df_merged, df_mergedGT'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b667a999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X = randomly_remove_indices(df_L2Normalized, 10)\\n#X[0]\\nX[1]'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''X = randomly_remove_indices(df_L2Normalized, 10)\n",
    "#X[0]\n",
    "X[1]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fe23fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomly_remove_indices1(df, percentage):\n",
    "    indices_to_remove = {}\n",
    "    groundTruth = {}\n",
    "    new_df = {}\n",
    "    num_indices = int(len(df) * percentage/100)\n",
    "    \n",
    "    for column in df.columns:\n",
    "        indices_to_remove[column] = np.random.choice(df[column].index, size=num_indices, replace=False)\n",
    "        groundTruth[column] = df[column].loc[indices_to_remove[column]].copy()\n",
    "        new_df[column] = df[column].copy()\n",
    "        new_df[column].loc[indices_to_remove[column]] = np.nan\n",
    "\n",
    "    # Merge the new DataFrames\n",
    "    df_merged = pd.concat(new_df.values(), axis=1)\n",
    "    df_mergedGT = pd.concat(groundTruth.values(), axis=1)\n",
    "\n",
    "    return df_merged, df_mergedGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c86e5ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.048480</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047237</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.048872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.046983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.049408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.049802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.052002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.050348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Length     Width    Height\n",
       "0         NaN  0.048480       NaN\n",
       "7         NaN       NaN  0.050630\n",
       "11        NaN  0.047237       NaN\n",
       "13        NaN       NaN  0.048872\n",
       "15   0.046983       NaN       NaN\n",
       "..        ...       ...       ...\n",
       "484       NaN       NaN  0.045694\n",
       "491  0.049408       NaN  0.047476\n",
       "495  0.049802       NaN       NaN\n",
       "498       NaN       NaN  0.052002\n",
       "499  0.050348       NaN       NaN\n",
       "\n",
       "[111 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = randomly_remove_indices1(df_L2Normalized, 10)\n",
    "X1[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e54752f",
   "metadata": {},
   "source": [
    "Data Imputation Methods\n",
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27f5c99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e36218a",
   "metadata": {},
   "source": [
    "Data Imputation Methods\n",
    "MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b17812d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db89e03b",
   "metadata": {},
   "source": [
    "Data Imputation Methods\n",
    "Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaf652e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a22cde12",
   "metadata": {},
   "source": [
    "Scoring Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8f7504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7029417c",
   "metadata": {},
   "source": [
    "Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac0f568",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
